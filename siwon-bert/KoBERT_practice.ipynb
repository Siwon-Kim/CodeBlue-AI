{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNynDSKdI/BN6pHaweAlqDN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Siwon-Kim/CodeBlue-AI/blob/develop/siwon/KoBERT_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mxnet\n",
        "!pip install gluonnlp pandas tqdm\n",
        "!pip install sentencepiece\n",
        "!pip install transformers\n",
        "!pip install torch"
      ],
      "metadata": {
        "id": "WHzK8RbmznDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'"
      ],
      "metadata": {
        "id": "2FgbiXvFHHE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install texlive texlive-xetex texlive-latex-extra pandoc\n",
        "!pip install pypandoc"
      ],
      "metadata": {
        "id": "WSYk-1nZ3wB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "0eWErEsL34gU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 증상 데이터와 응급 정도 레이블\n",
        "data = [\n",
        "    [\"10분 정도 한 후에 괜찮아짐.\", [0., 1., 0., 0., 0.]],\n",
        "    [\"밥을 먹다가 아랫입술이 경련이 난 것처럼 떨린다.\", [0., 0., 0., 1., 0.]],\n",
        "    [\"월요일 체력단련 후 명치가 아프면서 밤새 동안 구토, 구역질\", [0., 0., 1., 0., 0.]],\n",
        "    [\"교정하고 있는 상태.\", [1., 0., 0., 0., 0.]],\n",
        "    [\"운동을 하다가 심장이 갑자기 아프다.\", [0., 0., 1., 0., 0.]],\n",
        "    [\"증상은 1주일 정도 계속\", [0., 0., 1., 0., 0.]],\n",
        "    [\"가끔씩 어지럽거나 빈혈도 있음\", [0., 1., 0., 0., 0.]],\n",
        "    [\"혈압약을 먹고 있음\", [1., 0., 0., 0., 0.]],\n",
        "    [\"아스팔트에서 넘어져 살이 까지는 찰과상\", [0., 1., 0., 0., 0.]],\n",
        "    [\"다음날 상처 부위에 진물이 흐름\", [1., 0., 0., 0., 0.]],\n",
        "    [\"지금은 상처 주변이 빨갛게 변함\", [0., 1., 0., 0., 0.]],\n",
        "    [\"상처에서 열감이 느껴짐\", [0., 1., 0., 0., 0.]],\n",
        "    [\"담석증으로 인해 복강경 수술 후 [0., 0., 1., 0., 0.]일 뒤 퇴원\", [0., 0., 1., 0., 0.]],\n",
        "    [\"역류성 식도염 증상과 구역감이 지속\", [0., 0., 1., 0., 0.]],\n",
        "    [\"식사 후 구역감이 계속 생김\", [0., 0., 1., 0., 0.]],\n",
        "    [\"역류성 식도염처럼 목에 이물감이 계속 남아있음\", [0., 1., 0., 0., 0.]],\n",
        "    [\"4일 전 부터 잇몸이 너무 아프고 시림\", [0., 1., 0., 0., 0.]],\n",
        "    [\"출혈이 반복되며 소염 진통제를 먹어도 효과가 없음\", [0., 0., 0., 1., 0.]],\n",
        "    [\"잇몸이 헐고 열이 계속 남\", [0., 1., 0., 0., 0.]],\n",
        "    [\"바람이 불면 상처부위랑 얼굴이 아프고 식사를 제대로 못함\", [0., 0., 1., 0., 0.]],\n",
        "    [\"자고 일어났을 때 목과 어깨가 뻐근하고 찌릿한 느낌을 받음\", [1., 0., 0., 0., 0.]],\n",
        "    [\"오른쪽 귀 밑부터 쇄골 윗 부분 근육까지 아픔\", [0., 1., 0., 0., 0.]],\n",
        "    [\"교통사고 난 느낌일 정도로 아픔\", [0., 0., 1., 0., 0.]],\n",
        "    [\"얼굴 광대 아랫부분부터 입 주변 부분이 저림\", [0., 1., 0., 0., 0.]],\n",
        "    [\"통증은 없으며, 지릿지릿한 느낌이고 증상이 한번 발생하면 보통 [0., 0., 1., 0., 0.]~5시간 지속\", [0., 1., 0., 0., 0.]],\n",
        "    [\"정신과에 불안장애 진단을 받고 현재 약을 복용중\", [0., 0., 1., 0., 0.]],\n",
        "    [\"최근 들어 과호흡이 심해짐\", [0., 0., 1., 0., 0.]],\n",
        "    [\"호흡곤란 느낌이 이어지며 심장이 답답하고, 약을 복용 후에도 지속\", [0., 0., 1., 0., 0.]],\n",
        "    [\"일상생활이 힘든 정도\", [0., 0., 1., 0., 0.]],\n",
        "    [\"회사 근무 간 불안과 긴장, 한숨이 반복\", [1., 0., 0., 0., 0.]],\n",
        "    [\"본인의 직책에 대한 과도한 불안감\", [0., 1., 0., 0., 0.]],\n",
        "    [\"본인의 적응 능력에 대한 자책과 울적함을 느끼며, 과한 음주\", [0., 1., 0., 0., 0.]],\n",
        "    [\"긴장 완화를 위해 본인에게 맞지 않는 커피를 지속 섭취\", [1., 0., 0., 0., 0.]],\n",
        "    [\"피를 뽑은 후 바늘 구멍 주변이 모기물린 것 처럼 부어오름\", [1., 0., 0., 0., 0.]],\n",
        "    [\"간지럽고 1.~2달간 상처가 아물지 않음\", [0., 1., 0., 0., 0.]],\n",
        "    [\"이전에 극 민감성 아토피를 앓았던 적이 있음\", [0., 1., 0., 0., 0.]],\n",
        "    [\"6개월이 지난 지금은 주사부위만 트고 가끔 가려움\", [1., 0., 0., 0., 0.]],\n",
        "    [\"목을 오른쪽으로 꺾으면 가슴 명치 쪽이 쑤심\", [0., 1., 0., 0., 0.]],\n",
        "    [\"수면 중 기침 때문에 자다가 숨 넘어갈 것 같음\", [0., 1., 0., 0., 0.]],\n",
        "    [\"명치 왼쪽 부분이 쑤시는 느낌이 듬\", [0., 1., 0., 0., 0.]],\n",
        "    [\"정수리 오른쪽 뾰루지 부분에 바늘로 찌르는 듯한 심한 통증을 느낌\", [0., 1., 0., 0., 0.]],\n",
        "    [\"앞으로 휘청거려서 쓰러질 정도로 중심을 못잡음\", [0., 0., 1., 0., 0.]],\n",
        "    [\"심장이 따끔 거리고 호흡이 힘듬\", [0., 0., 1., 0., 0.]],\n",
        "    [\"의식이 없으며, 자가 호흡을 하지 못함\", [0., 0., 0., 0., 1.]],\n",
        "    [\"팔에 심한 출혈이 있으며, 맥박이 떨어짐\", [0., 0., 0., 0., 1.]],\n",
        "    [\"의식이 없으며 심박이 불안함\", [0., 0., 0., 0., 1.]],\n",
        "    [\"환자는 경기를 일으키고 있음\", [0., 0., 0., 1., 0.]],\n",
        "    [\"공황장애 병력을 갖고 있음\", [0., 0., 1., 0., 0.]],\n",
        "    [\"체온이 낮고 나른함\", [1., 0., 0., 0., 0.]],\n",
        "    [\"종아리가 심하게 부어있음\", [0., 1., 0., 0., 0.]],\n",
        "    [\"숨을 쉴 때 갑자기 흉부에 통증을 느낌\", [0., 1., 0., 0., 0.]],\n",
        "    [\"마른 기침이 나오며 숨을 쉬기 힘들어 합니다.\", [0., 0., 1., 0., 0.]],\n",
        "    [\"평소에 사과 알레르기가 있으며, 눈과 입술이 부어오름\", [0., 1., 0., 0., 0.]],\n",
        "    [\"원인 미상의 알레르기 반응으로 목 부분이 심하게 부었음\", [0., 0., 1., 0., 0.]],\n",
        "    [\"동공이 확장되었으며 식은 땀을 흘림\", [0., 0., 1., 0., 0.]],\n",
        "    [\"목이 심하게 부어 숨을 쉬는데 고통을 호소하고 있음\", [0., 0., 1., 0., 0.]],\n",
        "    [\"맥박이 떨어지고 있으며 의식이 없음\", [0., 0., 0., 0., 1.]],\n",
        "    [\"심한 두통과 고열 증세를 보임\", [0., 1., 0., 0., 0.]],\n",
        "    [\"몸이 건조하며 탈수 증상이 있음\", [0., 1., 0., 0., 0.]],\n",
        "    [\"정신착란 증세가 있으며 사물을 인지 못함\", [0., 0., 0., 1., 0.]],\n",
        "    [\"강한 뇌진탕으로 인하여 의식이 없음\", [0., 0., 0., 0., 1.]],\n",
        "    [\"엉덩이부근에 심한 찰과상이 있음\", [0., 1., 0., 0., 0.]],\n",
        "    [\"소실된 의식과 기억 상실, 혼란상태를 보여요.\", [0., 0., 0., 1., 0.]],\n",
        "    [\"환자가 오늘 아침에 발열이 높았다. 또한 환자가 혈압이 높았다.\", [0., 1., 0., 0., 0.]],\n",
        "    [\"두통으로 인해 치매 증상 발생\", [0., 0., 1., 0., 0.]],\n",
        "    [\"두통때문에 혼절함\", [0., 0., 0., 1., 0.]],\n",
        "    [\"두통, 치통이 있으며 오른쪽 팔목에 통증을 호소한다.\", [0., 1., 0., 0., 0.]],\n",
        "    [\"기억 상실상태이며, 가끔 가슴통증도 동반한다\", [0., 1., 0., 0., 0.]],\n",
        "    [\"기운이 없으며 손발이 계속 저리고, 청각이 손실 된듯 하다\", [0., 0., 1., 0., 0.]],\n",
        "    [\"피를 계속 토하고, 각혈이 지속되다보니 혈압이 높아져서 쓰러짐\", [0., 0., 0., 0., 1.]],\n",
        "    [\"심부전의 징후인 가슴 통증, 사지 부종, 코막힘이 있어요.\", [0., 0., 0., 1., 0.]],\n",
        "    [\"발작으로 인한 청각 손실, 시야 손실 발생했습니다.\", [0., 0., 0., 1., 0.]],\n",
        "    [\"호흡곤란과 호흡음, 흉부 압박감을 겪고 있습니다.\", [0., 0., 0., 1., 0.]],\n",
        "    [\"고열과 목의 부종 사지 마비로 도움이 필요해 보입니다.\", [0., 0., 0., 0., 1.]],\n",
        "    [\"팔과 다리 부분에 1.도 화상을 입었습니다.\", [0., 1., 0., 0., 0.]],\n",
        "    [\"전신에 힘이 없으며 몸을 제대로 가누지를 못함\", [0., 1., 0., 0., 0.]],\n",
        "    [\"혈압이 높고 경련 증세가 있음\", [0., 0., 1., 0., 0.]],\n",
        "    [\"사물을 인지하지 못하고 상황판단이 불가능함\", [0., 0., 1., 0., 0.]],\n",
        "    [\"엉덩이에서 작은 출혈이 있음\", [1., 0., 0., 0., 0.]],\n",
        "    [\"등에 멍자국이 있음\", [1., 0., 0., 0., 0.]],\n",
        "    [\"얼굴에 붉은 반점이 있음\", [1., 0., 0., 0., 0.]],\n",
        "    [\"안면부에 심한 찰과상이 있으며 출혈이 심합니다\", [0., 0., 1., 0., 0.]],\n",
        "    [\"기침에 피를 동반함\", [0., 0., 1., 0., 0.]],\n",
        "    [\"어깨 부근의 탈골이 의심됨.\", [1., 0., 0., 0., 0.]],\n",
        "    [\"빈혈끼가 있으며 시야가 보이지 않음\", [0., 0., 1., 0., 0.]],\n",
        "    [\"앞가슴을 심하게 누르는 듯한 느낌을 받음\", [0., 0., 1., 0., 0.]],\n",
        "    [\"환자의 전신에 자해 자국이 있음\", [0., 0., 1., 0., 0.]],\n",
        "    [\"다소 심한 뇌진탕으로 인해 의식이 희미함\", [0., 0., 0., 1., 0.]],\n",
        "    [\"목 부근에 자해의 흔적이 있다\", [0., 0., 0., 1., 0.]],\n",
        "    [\"코피 음식 섭취 곤란, 가려운 발진이 관찰되어요.\", [0., 1., 0., 0., 0.]],\n",
        "    [\"피토 하고, 각혈이 점점 심해져서 즉각적인 응급 처치가 필요함\", [0., 0., 0., 0., 1.]],\n",
        "    [\"오전에 발작을 일으켰으며 기운이 없어보이고, 호흡곤란이 있엇다\", [0., 0., 0., 1., 0.]],\n",
        "    [\"빈혈과 혈액 흘림, 황달 증상을 확인했습니다.\", [0., 0., 1., 0., 0.]],\n",
        "    [\"경련, 목의 부종, 의식 변화로 급한 조치가 필요해보입니다.\", [0., 0., 0., 0., 1.]],\n",
        "    [\"환자는 객혈과 피토를 겪고 있습니다.\", [0., 0., 0., 0., 1.]],\n",
        "    [\"기침을 자주하며 목이 심하게 부어오름\", [1., 0., 0., 0., 0.]],\n",
        "    [\"무릎에 심한 출혈이 있습니다\", [0., 0., 1., 0., 0.]],\n",
        "    [\"전신에 격통을 느끼고 있음\", [0., 0., 0., 1., 0.]],\n",
        "    [\"심한 발열과 함께 방금 있었던 일을 기억하지 못하는 등의 증세를 보임\", [0., 0., 0., 1., 0.]],\n",
        "    [\"자가 호흡이 불가능하며 빠른 이송이 필요\", [0., 0., 0., 0., 1.]],\n",
        "]"
      ],
      "metadata": {
        "id": "y062G51PMTso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KoBERT Tokenizer 가져오기\n",
        "\n",
        "from kobert_tokenizer import KoBERTTokenizer\n",
        "MODEL_NAME = \"skt/kobert-base-v1\"\n",
        "tokenizer = KoBERTTokenizer.from_pretrained(MODEL_NAME)\n",
        "tokenizer.encode(\"한국어 모델을 공유합니다.\")"
      ],
      "metadata": {
        "id": "WFL9uWO90x8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class SymptomsDataset(Dataset):\n",
        "    # 데이터셋을 전 처리해주는 함수\n",
        "    def __init__(self, dataset, tokenizer: KoBERTTokenizer, max_token_len: int = 128):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.dataset = dataset\n",
        "        self.max_token_len = max_token_len\n",
        "\n",
        "    def __len__(self):\n",
        "        # 데이터의 길이를 반환\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        # i번째 데이터 샘플을 선택할 때 즉, dataset [i]를 쓸 때 해당 값을 인코딩하여 반환\n",
        "        sentence, labels = self.dataset[i]\n",
        "     \n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            sentence,\n",
        "            add_special_tokens=True, # 토큰의 시작점에 [CLS], 마지막에 [SEP] 토큰을 붙임\n",
        "            max_length=self.max_token_len,\n",
        "            return_token_type_ids=False, # 두 개의 시퀀스 입력으로 활용할 때 0과 1로 문장의 토큰 값을 분리\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_attention_mask=True, # 패딩 된 부분을 알려주기 위해 사용되는 mask\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "\n",
        "        return dict(\n",
        "            sentence = sentence,\n",
        "            input_ids = encoding[\"input_ids\"].squeeze(),\n",
        "            attention_mask = encoding[\"attention_mask\"].squeeze(),\n",
        "            labels = torch.FloatTensor(labels)\n",
        "        )"
      ],
      "metadata": {
        "id": "PYpP3pOK7VaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader 만들기\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dataset = SymptomsDataset(data, tokenizer)\n",
        "sample_item = dataset[0]\n",
        "sample_item.keys()"
      ],
      "metadata": {
        "id": "KD8P40Cza6DW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample_item[\"sentence\"])\n",
        "print(sample_item[\"input_ids\"])\n",
        "print(sample_item[\"labels\"])"
      ],
      "metadata": {
        "id": "ZXefX7aMvIoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로더에 데이터셋을 담고 next(iter.. 를 사용하여 순회 가능한 데이터를 만들어 줄 수 있음\n",
        "sample_batch = next(iter(DataLoader(dataset, batch_size = 8, num_workers = 2 )))  \n",
        "sample_batch[\"input_ids\"].shape, sample_batch[\"attention_mask\"].shape"
      ],
      "metadata": {
        "id": "QNc0si-ru27K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KoBERT 모델 가져오기\n",
        "from transformers import BertModel\n",
        "\n",
        "bert_model = BertModel.from_pretrained(MODEL_NAME, return_dict=True)\n",
        "\n",
        "output = bert_model(sample_batch[\"input_ids\"], sample_batch[\"attention_mask\"])\n",
        "print(output)"
      ],
      "metadata": {
        "id": "m0_0WdZ19p7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch Lightning으로 Dataset 튜닝\n",
        "!pip install pytorch_lightning"
      ],
      "metadata": {
        "id": "DNHPIeBhiCah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "from torchmetrics.functional import accuracy,f1_score,auroc\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from pytorch_lightning.loggers import TensorBoardLogger"
      ],
      "metadata": {
        "id": "stRLYCJgiKSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader와 Dataset 지정 => 해당 DataLoader에 dataset과 batch_size, num_workers를 지정\n",
        "class SymptomsDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, train_df, test_df, tokenizer, batch_size = 8, max_token_len = 128):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.train_df = train_df\n",
        "        self.test_df = test_df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_token_len = max_token_len\n",
        "\n",
        "    def setup(self, stage = None):\n",
        "        self.train_dataset = SymptomsDataset(\n",
        "            self.train_df,\n",
        "            self.tokenizer,\n",
        "            self.max_token_len\n",
        "        )\n",
        "\n",
        "        self.test_dataset = SymptomsDataset(\n",
        "            self.test_df,\n",
        "            self.tokenizer,\n",
        "            self.max_token_len\n",
        "        )\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.train_dataset,\n",
        "            batch_size = self.batch_size,\n",
        "            shuffle = True,\n",
        "            num_workers = 2\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.batch_size,\n",
        "            batch_size = self.batch_size,\n",
        "            num_workers=2\n",
        "        )\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.test_dataset,\n",
        "            batch_size = self.batch_size,\n",
        "            num_workers = 2\n",
        "        )"
      ],
      "metadata": {
        "id": "e7YRkptgiVn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_dataloader & test_dataloader 만들기\n",
        "\n",
        "N_EPOCHS = 5\n",
        "BATCH_SIZE = 12\n",
        "MAX_TOKEN_COUNT = 128\n",
        "\n",
        "data_module = SymptomsDataModule(\n",
        "    data, # for training\n",
        "    data, # for testing\n",
        "    tokenizer,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    max_token_len = MAX_TOKEN_COUNT\n",
        ")\n",
        "print(data_module)"
      ],
      "metadata": {
        "id": "jHFUZG28kbEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch Lightning에서 trainer와 모델의 상호작용을 위해 lightning module을 만들어준다.\n",
        "\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "import torch.nn as nn\n",
        "\n",
        "LABEL_COLUMNS = [\"1,\" \"2\", \"3\", \"4\", \"5\"]\n",
        "\n",
        "class SymptomsSentencesTagger(pl.LightningModule):\n",
        "    def __init__(self, n_classes: int, n_training_steps=None, n_warmup_steps=None):\n",
        "        super().__init__()\n",
        "        self.bert = bert_model\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "        self.n_training_steps = n_training_steps\n",
        "        self.n_warmup_steps = n_warmup_steps\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.fc = nn.Linear(self.bert.config.hidden_size, len(LABEL_COLUMNS))\n",
        "\n",
        "    # 모델의 추론 결과를 제공하고 싶을 때 사용\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        output = self.bert(input_ids, attention_mask = attention_mask)\n",
        "        output = self.fc(output.pooler_output)\n",
        "        output = torch.sigmoid(output)\n",
        "        loss = 0\n",
        "        if labels is not None:\n",
        "            loss = self.criterion(output, labels)\n",
        "        return loss, output\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        labels = batch[\"labels\"]\n",
        "        loss,outputs = self(input_ids, attention_mask, labels)\n",
        "        self.log(\"val_loss\", loss, prog_bar =True, logger = True)\n",
        "        return {\"loss\": loss, \"predictions\": outputs, \"labels\": labels}\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        labels = batch[\"labels\"]\n",
        "        loss,outputs = self(input_ids, attention_mask, labels)\n",
        "        self.log(\"val_loss\", loss, prog_bar =True, logger = True)\n",
        "        return loss\n",
        "\n",
        "    def on_train_epoch_end(self, outputs):\n",
        "        labels = []\n",
        "        predictions = []\n",
        "        for output in outputs:\n",
        "            for out_labels in output[\"labels\"].detach().cpu():\n",
        "                labels.append(out_labels)\n",
        "            for out_predictions in output[\"predictions\"].detach().cpu():\n",
        "                predictions.append(out_predictions)\n",
        "\n",
        "        labels = torch.stack(labels).int()\n",
        "        predictions = torch.stack(predictions)\n",
        "\n",
        "        for i, name in enumerate(LABEL_COLUMNS):\n",
        "            class_roc_auc = auroc(predictions[:,i],labels[:,i])\n",
        "            self.logger.experiment.add_scalar(f\"{name}_roc_auc/Train\", class_roc_auc, self.current_epoch)\n",
        "    \n",
        "    # optimizer & scheduler 정\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = AdamW(self.parameters(), lr= 2e-5)\n",
        "\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer,\n",
        "            num_warmup_steps= self.n_warmup_steps,\n",
        "            num_training_steps = self.n_training_steps\n",
        "        )\n",
        "\n",
        "        return dict(\n",
        "            optimizer=optimizer,\n",
        "            lr_scheduler = dict(\n",
        "            scheduler = scheduler,\n",
        "            interval='step'\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "id": "v6KOmgv5k1ra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "dummy_model = nn.Linear(2,1)\n",
        "\n",
        "optimizer = AdamW(params=dummy_model.parameters(),lr=0.001)\n",
        "\n",
        "warmup_steps = 20\n",
        "total_training_steps = 100\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps = warmup_steps,\n",
        "    num_training_steps = total_training_steps\n",
        ")\n",
        "\n",
        "learning_rate_history = []\n",
        "\n",
        "for step in range(total_training_steps):\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    learning_rate_history.append(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "plt.plot(learning_rate_history, label=\"learning rate\")\n",
        "plt.axvline(x=warmup_steps, color=\"red\", linestyle=(0, (5, 10)), label=\"warmup end\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Step\")\n",
        "plt.ylabel(\"Learning rate\")\n",
        "plt.tight_layout();"
      ],
      "metadata": {
        "id": "yyJTBDnjqFZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = len(data)\n",
        "total_training_steps = steps_per_epoch * N_EPOCHS "
      ],
      "metadata": {
        "id": "uwLbwIa1qKhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warmup_steps = total_training_steps // 5\n",
        "warmup_steps, total_training_steps"
      ],
      "metadata": {
        "id": "mupUUASKqLE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SymptomsSentencesTagger(\n",
        "    n_classes=len(LABEL_COLUMNS),\n",
        "    n_warmup_steps = warmup_steps,\n",
        "    n_training_steps = total_training_steps\n",
        ")"
      ],
      "metadata": {
        "id": "_lMSdIphphlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 체크포인트\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "  dirpath=\"checkpoints\",\n",
        "  filename=\"best-checkpoint\",\n",
        "  save_top_k=1,\n",
        "  verbose=True,\n",
        "  monitor=\"val_loss\",\n",
        "  mode=\"min\"\n",
        ")"
      ],
      "metadata": {
        "id": "32Ii89YJncUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger = TensorBoardLogger(\"lightning_logs\", name=\"symptoms-sentences\")\n",
        "\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=2)"
      ],
      "metadata": {
        "id": "VfWHAnthnk9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = pl.Trainer(\n",
        "  logger=logger,\n",
        "  callbacks=[checkpoint_callback, early_stopping_callback],\n",
        "  max_epochs=N_EPOCHS,\n",
        "  accelerator=\"gpu\", \n",
        ")\n",
        "\n",
        "trainer.fit(model, data_module)"
      ],
      "metadata": {
        "id": "BczEYdXcntPN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}